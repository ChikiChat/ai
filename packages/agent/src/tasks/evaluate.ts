import {generateText} from "ai";
import {DEFAULT_EMBEDDING_MODEL_NAME, languageModel, LanguageModelInit} from "@chikichat/model";
import {Dataset} from "../dataset";
import {PromptEvaluate} from "../prompts";
import {Task} from "./task";
import {TaskSimilarity} from "./similarity";

/**
 * Type definition for the result of an evaluation task.
 */
type Result = {
    /**
     * The original statement from the dataset.
     */
    statement: string;

    /**
     * The expected answer based on the dataset.
     */
    expect: string;

    /**
     * The actual answer generated by the language model.
     */
    answer: string;

    /**
     * The similarity score between the expected and actual answers.
     */
    similarity: number;
}

/**
 * Task to evaluate a language model using a dataset.
 */
export class TaskEvaluate extends Task<Result[]> {
    private readonly dataset: Dataset;
    private readonly similarity: TaskSimilarity;

    /**
     * Constructs a new TaskEvaluate instance.
     *
     * @param {string} datasetPath - The path to the dataset file.
     * @param {string} [embeddingModel=DEFAULT_EMBEDDING_MODEL_NAME] - The name of the embedding model to use.
     */
    constructor(datasetPath: string, embeddingModel: string = DEFAULT_EMBEDDING_MODEL_NAME) {
        super('Evaluate', 'Evaluates the language model using the dataset.');

        this.dataset = new Dataset(datasetPath);
        this.similarity = new TaskSimilarity(embeddingModel);
    }

    /**
     * Runs the evaluation task.
     *
     * @param {LanguageModelInit} init - The initialization configuration for the language model.
     * @returns {Promise<Result[]>} - A promise that resolves to an array of evaluation results.
     */
    async run(init: LanguageModelInit): Promise<Result[]> {
        const results: Result[] = [];
        const prompt = PromptEvaluate;

        for (const sample of this.dataset.values()) {
            const {text} = await generateText({
                prompt: prompt.toString({statement: sample.statement}),
                model: languageModel(init.model),
                maxTokens: init.maxTokens,
                maxSteps: init.maxSteps,
                temperature: init.temperature,
                topP: init.topP,
                topK: init.topK,
                presencePenalty: init.presencePenalty,
                frequencyPenalty: init.frequencyPenalty,
            });

            const answer = prompt.parse(text);
            results.push({
                statement: sample.statement,
                expect: sample.expect,
                answer: answer,
                similarity: await this.similarity.run(sample.expect, answer)
            } as Result);
        }

        return results;
    }
}
