import {EmbeddingModel, LanguageModel} from "ai";
import {createGoogleGenerativeAI, GoogleGenerativeAIProvider} from "@ai-sdk/google";
import {Provider} from '../provider';
import {RequestInit} from "../../types";

export class GoogleGenerativeAI extends Provider {
    id = 'google-generative-ai';
    name = 'Google Generative AI';
    description = `Create, discover, summarize and automate with Google Cloud's generative AI products and services`;
    models = [
        {
            id: `${this.id}/gemini-2.5-pro-preview-03-25`,
            name: 'Gemini 2.5 Pro Preview 03-25',
            description: `State-of-the-art multipurpose model, which excels at coding and complex reasoning tasks`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 1048576, output: 65536},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000001000, output: 0.0000004000},
        },
        {
            id: `${this.id}/gemini-2.0-flash`,
            name: 'Gemini 2.0 Flash',
            description: `Most capable multi-modal model with great performance across all tasks, with a 1 million token context window, and built for the era of Agents`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 1048576, output: 8192},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000001000, output: 0.0000004000},
        },
        {
            id: `${this.id}/gemini-2.0-flash-lite`,
            name: 'Gemini 2.0 Flash-Lite',
            description: `Smallest and most cost effective model, built for at scale usage`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 1048576, output: 8192},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000000750, output: 0.0000003000},
        },
        {
            id: `${this.id}/gemini-2.0-flash-thinking-exp-01-21`,
            name: 'Gemini 2.0 Flash Thinking Experimental 01-21',
            description: `Gemini 2.0 Flash Thinking Mode is an experimental model that's trained to generate the "thinking process" the model goes through as part of its response`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: false,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 1048576, output: 65536},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/gemini-1.5-flash`,
            name: 'Gemini 1.5 Flash',
            description: `Fastest multimodal model with great performance for diverse, repetitive tasks and a 1 million token context window`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 1000000, output: 8192},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000000750, output: 0.0000003000},
        },
        {
            id: `${this.id}/gemini-1.5-flash-8b`,
            name: 'Gemini 1.5 Flash-8B',
            description: `Smallest model for lower intelligence use cases, with a 1 million token context window`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 1000000, output: 8192},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000000375, output: 0.0000001500},
        },
        {
            id: `${this.id}/gemini-1.5-pro`,
            name: 'Gemini 1.5 Pro',
            description: `Highest intelligence Gemini 1.5 series model, with a breakthrough 2 million token context window`,
            architecture: '',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 0, input: 2000000, output: 8192},
                text: {input: true, output: true},
                image: {input: true, output: false},
                audio: {input: true, output: false},
                video: {input: true, output: false},
            },
            price: {input: 0.0000012500, output: 0.0000050000},
        },
        {
            id: `${this.id}/gemma-3-27b-it`,
            name: 'Gemma 3 (27B)',
            description: `Lightweight, state-of the art, open model built from the same technology that powers Gemini models`,
            architecture: 'Gemma3ForConditionalGeneration',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 262144, embedding: 5376, input: 131072, output: 8192},
                text: {input: true, output: true},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/gemma-3-12b-it`,
            name: 'Gemma 3 (12B)',
            description: `Lightweight, state-of the art, open model built from the same technology that powers Gemini models`,
            architecture: 'Gemma3ForConditionalGeneration',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 262144, embedding: 3840, input: 32768, output: 8192},
                text: {input: true, output: true},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/gemma-3-4b-it`,
            name: 'Gemma 3 (4B)',
            description: `Lightweight, state-of the art, open model built from the same technology that powers Gemini models`,
            architecture: 'Gemma3ForConditionalGeneration',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 262144, embedding: 2560, input: 32768, output: 8192},
                text: {input: true, output: true},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/gemma-3-1b-it`,
            name: 'Gemma 3 (1B)',
            description: `Lightweight, state-of the art, open model built from the same technology that powers Gemini models`,
            architecture: 'Gemma3ForCausalLM',
            capabilities: {
                embedding: false,
                tool_call: true,
                rerank: false,
                features: [],
                size: {vocab: 262144, embedding: 1152, input: 32768, output: 8192},
                text: {input: true, output: true},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/gemini-embedding-exp`,
            name: 'Gemini Embedding Experimental',
            description: `Obtain a distributed representation of a text`,
            architecture: '',
            capabilities: {
                embedding: true,
                tool_call: false,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 3072, input: 8192, output: 0},
                text: {input: true, output: false},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/text-embedding-004`,
            name: 'Text Embedding 004',
            description: `Obtain a distributed representation of a text`,
            architecture: '',
            capabilities: {
                embedding: true,
                tool_call: false,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 768, input: 2048, output: 0},
                text: {input: true, output: false},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
        {
            id: `${this.id}/embedding-001`,
            name: 'Embedding 001',
            description: `Obtain a distributed representation of a text`,
            architecture: '',
            capabilities: {
                embedding: true,
                tool_call: false,
                rerank: false,
                features: [],
                size: {vocab: 0, embedding: 768, input: 2048, output: 0},
                text: {input: true, output: false},
                image: {input: false, output: false},
                audio: {input: false, output: false},
                video: {input: false, output: false},
            },
            price: {input: 0.0000000000, output: 0.0000000000},
        },
    ];
    default = {
        baseURL: 'https://generativelanguage.googleapis.com/v1beta',
        pricingURL: 'https://ai.google.dev/pricing',
        manageAPIKeysURL: 'https://aistudio.google.com/app/apikey',
        model: 'gemini-1.5-flash-8b-latest',
    };

    create(init: RequestInit = {}): GoogleGenerativeAIProvider {
        return createGoogleGenerativeAI({baseURL: this.baseUrl(init.baseURL), apiKey: this.apiKey(init.apiKey), headers: init.headers});
    }

    languageModel(model: string, init: RequestInit = {}): LanguageModel {
        return this.create(init)(model);
    }

    embeddingModel(model: string, init: RequestInit = {}): EmbeddingModel<string> {
        return this.create(init).textEmbeddingModel(model);
    }
}